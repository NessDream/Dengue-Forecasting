{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.B - Hands-on - pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### How to manipulate data with Python?\n",
    "\n",
    "#### Manipulating dataframe with pyhton\n",
    "\n",
    "Matrix are pretty well adapted to compute mathematical scoring or adapted for many financial topics. \n",
    "However, when it comes to deal with data client, it presents different limitations. One main limitation is that you cannot mix types inside a matrix.  \n",
    "\n",
    "The most famous library to manipulate data is `pandas`. It provides a large amount of functionalities similar to SAS (select, groupby, filter, etc.). \n",
    "\n",
    "The following script introduces common operation you can lead with pandas. We will see in the next session how to use them on an insurance dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-08T11:47:23.273000Z",
     "start_time": "2018-05-08T11:47:23.266000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import of the library: we tag it as np to avoid us writting the full name each time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to set you path directory, you might need the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-08T11:48:52.553000Z",
     "start_time": "2018-05-08T11:48:52.544000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#os.getcwd()\n",
    "#os.chdir('.\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading a dataframe\n",
    "It is pretty straightforward as in Matlab.\n",
    "\n",
    "```Matlab\n",
    "\n",
    "filename = 'titanic_train.csv';\n",
    "delimiterIn = ',';\n",
    "headerlinesIn = 1;\n",
    "df = importdata(filename,delimiterIn,headerlinesIn);\n",
    "```\n",
    "\n",
    "In SAS you would have needed a little bit more lines.\n",
    "\n",
    "```SAS\n",
    "proc import datafile=\"C:\\temp\\titanic_train.csv\"\n",
    "     out=df\n",
    "     dbms=csv\n",
    "     replace;\n",
    "     getnames=no;\n",
    "run;\n",
    "``` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-08T11:36:48.870000Z",
     "start_time": "2018-05-08T11:36:48.856000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '../materials/titanic_train.csv'\n",
    "df = pd.read_csv(path,delimiter=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-08T11:37:06.322000Z",
     "start_time": "2018-05-08T11:37:06.306000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-08T11:37:30.026000Z",
     "start_time": "2018-05-08T11:37:30.015000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get columns name\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T21:02:29.673000Z",
     "start_time": "2018-04-30T21:02:29.637000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get first rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-08T11:59:06.396000Z",
     "start_time": "2018-05-08T11:59:06.383000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get a column by its name and apply head method on result\n",
    "df[[\"PassengerId\",\"Survived\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-08T12:00:02.068000Z",
     "start_time": "2018-05-08T12:00:02.057000Z"
    }
   },
   "source": [
    "Schema of dataframes is discribed with python numpy dtype object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T21:02:30.289000Z",
     "start_time": "2018-04-30T21:02:30.277000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print schema\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T21:02:30.494000Z",
     "start_time": "2018-04-30T21:02:30.483000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test type of a column\n",
    "name = 'Fare'\n",
    "df[name].dtype == np.float64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas has a \"describe\" method that can print a quick overview of your data. However, it gives only description of numerical values if types are mixed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-08T11:41:58.342000Z",
     "start_time": "2018-05-08T11:41:58.302000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another method (value_counts) allows the user to analyse qualitative columns in details one by one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T21:02:31.355000Z",
     "start_time": "2018-04-30T21:02:31.337000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#count occurences of each modality: equivalent to groupby and count\n",
    "df[\"Sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exercise 8 ** \n",
    "\n",
    "By using previous methods write a function 'summary' that output a complete description of the dataframe. \n",
    "\n",
    "We can for instance test the type of the column and return either describe result or value_counts result according to the type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-08T12:09:41.369000Z",
     "start_time": "2018-05-08T12:09:41.360000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-08T12:09:51.230000Z",
     "start_time": "2018-05-08T12:09:51.175000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulating data with pandas\n",
    "\n",
    "As mentionned previously, traditional operations on structure data are available within pandas. The object oriented programmation allows to compute a pipeline of actions by calling methods in a successive way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-08T12:12:02.822000Z",
     "start_time": "2018-05-08T12:12:02.806000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#select columns\n",
    "df[['Sex','PassengerId']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-08T12:12:48.258000Z",
     "start_time": "2018-05-08T12:12:48.245000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#groupby columns\n",
    "df.groupby(['Sex','Pclass'])['Survived'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exercise 9** \n",
    "\n",
    "Compute the Average Fare price (Fare) per class (Pclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-08T12:16:24.717000Z",
     "start_time": "2018-05-08T12:16:24.702000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-08T12:17:43.699000Z",
     "start_time": "2018-05-08T12:17:43.674000Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#filtering \n",
    "df[df['Sex'] =='male'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-08T12:18:08.729000Z",
     "start_time": "2018-05-08T12:18:08.717000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#adding new column based on existing columns\n",
    "df['newcol'] = len(df['Sex'].unique())\n",
    "df['newcol'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-08T12:19:47.071000Z",
     "start_time": "2018-05-08T12:19:47.056000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['newcol2']= df['Sex']+ df['Pclass'].astype(np.str) #we convert Pclass column into string\n",
    "df['newcol2'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-08T12:20:18.395000Z",
     "start_time": "2018-05-08T12:20:18.387000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adding a lag column: could be useful for timeseries manipulation\n",
    "df['Age_lag']=df['Age'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-08T12:20:21.434000Z",
     "start_time": "2018-05-08T12:20:21.419000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[['Age_lag',\"Age\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T21:02:35.607000Z",
     "start_time": "2018-04-30T21:02:35.585000Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating  bucket with pandas\n",
    "pd.cut(df['Age'],[0,18,25,50,100],labels=[\"child\",\"youngAdult\",\"adult\",\"senior\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T21:02:35.825000Z",
     "start_time": "2018-04-30T21:02:35.781000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#applying a specific transformation: example of creation of one column containing the concatenation of eahn column\n",
    "def concat(x):\n",
    "    return(\"\".join(map(str,x)))\n",
    "\n",
    "df.apply(concat,axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exercise 10**\n",
    "\n",
    "By using  apply, cut and a groupby methods, write a code that analyze the Survival rate according to the length of the name variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-08T12:42:27.738000Z",
     "start_time": "2018-05-08T12:42:27.715000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T08:34:38.864000Z",
     "start_time": "2018-05-01T08:34:38.734000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#selecting lines with nulls\n",
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T08:37:08.815000Z",
     "start_time": "2018-05-01T08:37:08.803000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#selecting a specific values from its index and column name\n",
    "df.loc[0,['Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T08:37:57.777000Z",
     "start_time": "2018-05-01T08:37:57.667000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drop column with NA\n",
    "df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-08T12:46:21.530000Z",
     "start_time": "2018-05-08T12:46:21.490000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#replace specific value in a column:  passed by referencep\n",
    "print(df['Age'].isnull().sum())\n",
    "df['Age'][df['Age'].isnull()]=df['Age'].mean()\n",
    "\n",
    "print(df['Age'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T12:35:04.184000Z",
     "start_time": "2018-05-01T12:35:04.104000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sampling returning only one sample\n",
    "df.sample(frac=0.8,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### link between pandas and numpy\n",
    "It is easy to convert a pandas object into a numpy object if needed. It will be all the more useful when we will try to model by using either a statistic or machinelearning model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T21:02:36.900000Z",
     "start_time": "2018-04-30T21:02:36.866000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#converting to numpy\n",
    "print(df.values)\n",
    "type(df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing data with pandas\n",
    "\n",
    "pandas has also some plot functionalities that can be used to have a quick overview of your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T21:02:38.269000Z",
     "start_time": "2018-04-30T21:02:37.958000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df['Sex'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exercise 11 **\n",
    "\n",
    "Plot the distribution of Age per Sex. You can plot two different graphics. We will see in the next part how to plot this in one command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Extra) Streaming data with python\n",
    "\n",
    "Whereas <b>SAS</b>, pandas is in memory. That means it load the full information into RAM memory. This could lead to memory issues if your data is pretty big relatively to your RAM. In that cas, you could be still interested in reading for instance the first line of the file. \n",
    "\n",
    "We can do this with python by using buffers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T14:21:01.413000Z",
     "start_time": "2018-05-01T14:21:01.397000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mybuff = open('../materials/titanic_train.csv','r') # this create a connection between python and the file \n",
    "#'r'  argument precise we will just read the file, if you want to edit it use 'w' for writing or 'a' for appending\n",
    "\n",
    "mybuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the connection made, the object behave like a cursor initially pointing the beginning of the file.\n",
    "Each time you call a command to read what contains the cursor, it returns results and then moves to the line after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T14:21:30.608000Z",
     "start_time": "2018-05-01T14:21:30.588000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reading the first line\n",
    "mybuff.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T14:23:07.705000Z",
     "start_time": "2018-05-01T14:23:07.689000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calling again\n",
    "mybuff.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T14:23:54.375000Z",
     "start_time": "2018-05-01T14:23:54.359000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getting the 5 first line\n",
    "result = []\n",
    "mybuff = open('../materials/titanic_train.csv','r')\n",
    "for i in range(5):\n",
    "    result.append(mybuff.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T14:23:59.232000Z",
     "start_time": "2018-05-01T14:23:59.220000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method gives you a raw data, you then have to retreat to transform it into a dataframe. \n",
    "\n",
    "**remark** \n",
    "\n",
    "For information, pandas implement a similar reading option (chunk size). You need to read carefully the documentation for more details. You can also refer to the 'dask' library for another way to analyse big file on a small computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:python-training]",
   "language": "python",
   "name": "conda-env-python-training-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
